# SuperAI Platform - ConfigMaps
apiVersion: v1
kind: ConfigMap
metadata:
  name: superai-config
  namespace: superai
  labels:
    app.kubernetes.io/name: superai-platform
data:
  SUPERAI_ENVIRONMENT: "production"
  SUPERAI_LOG_LEVEL: "INFO"
  SUPERAI_HOST: "0.0.0.0"
  SUPERAI_PORT: "8000"
  SUPERAI_WORKERS: "4"
  SUPERAI_DEFAULT_ENGINE: "vllm"
  SUPERAI_ENGINE_TIMEOUT_SECONDS: "120"
  SUPERAI_MAX_CONCURRENT_REQUESTS: "256"
  SUPERAI_REQUEST_QUEUE_SIZE: "4096"
  SUPERAI_VLLM_HOST: "vllm-svc"
  SUPERAI_VLLM_PORT: "8001"
  SUPERAI_VLLM_GPU_MEMORY_UTILIZATION: "0.90"
  SUPERAI_VLLM_MAX_MODEL_LEN: "32768"
  SUPERAI_VLLM_TENSOR_PARALLEL_SIZE: "1"
  SUPERAI_TGI_HOST: "tgi-svc"
  SUPERAI_TGI_PORT: "8002"
  SUPERAI_SGLANG_HOST: "sglang-svc"
  SUPERAI_SGLANG_PORT: "8003"
  SUPERAI_OLLAMA_HOST: "ollama-svc"
  SUPERAI_OLLAMA_PORT: "11434"
  SUPERAI_TENSORRT_HOST: "tensorrt-svc"
  SUPERAI_TENSORRT_PORT: "8004"
  SUPERAI_LMDEPLOY_HOST: "lmdeploy-svc"
  SUPERAI_LMDEPLOY_PORT: "8005"
  SUPERAI_REDIS_HOST: "redis-svc"
  SUPERAI_REDIS_PORT: "6379"
  SUPERAI_POSTGRES_HOST: "postgres-svc"
  SUPERAI_POSTGRES_PORT: "5432"
  SUPERAI_POSTGRES_DB: "superai"
  SUPERAI_MODEL_CACHE_DIR: "/models"
  SUPERAI_DEFAULT_MODEL: "meta-llama/Llama-3.1-8B-Instruct"
  SUPERAI_VISION_MODEL: "Qwen/Qwen2.5-VL-7B-Instruct"
  SUPERAI_WHISPER_MODEL: "openai/whisper-large-v3-turbo"
  SUPERAI_EMBEDDING_MODEL: "BAAI/bge-large-en-v1.5"
  SUPERAI_VECTOR_DB_HOST: "milvus-svc"
  SUPERAI_VECTOR_DB_PORT: "19530"
  SUPERAI_ENABLE_TRACING: "true"
---
apiVersion: v1
kind: Secret
metadata:
  name: superai-secrets
  namespace: superai
  labels:
    app.kubernetes.io/name: superai-platform
type: Opaque
stringData:
  SUPERAI_SECRET_KEY: "k8s-production-change-me-openssl-rand-hex-32"
  SUPERAI_POSTGRES_USER: "superai"
  SUPERAI_POSTGRES_PASSWORD: "superai_secret_k8s"
  SUPERAI_REDIS_PASSWORD: ""
  HF_TOKEN: ""