apiVersion: batch/v1
kind: CronJob
metadata:
  name: superai-db-backup
  namespace: eco-superai
  labels:
    app.kubernetes.io/name: superai-platform
    app.kubernetes.io/component: backup
spec:
  schedule: "0 2 * * *"
  timeZone: "UTC"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  startingDeadlineSeconds: 600
  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 1800
      template:
        metadata:
          labels:
            app.kubernetes.io/name: superai-platform
            app.kubernetes.io/component: backup
        spec:
          restartPolicy: OnFailure
          serviceAccountName: superai-worker
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            runAsGroup: 1000
          containers:
            - name: db-backup
              image: postgres:16-alpine
              command:
                - /bin/sh
                - -c
                - |
                  set -euo pipefail
                  TIMESTAMP=$(date +%Y%m%d_%H%M%S)
                  BACKUP_FILE="/backups/superai_db_${TIMESTAMP}.sql.gz"
                  echo "[backup] Starting database backup..."
                  pg_dump -h "${DB_HOST}" -U "${DB_USER}" -d "${DB_NAME}" \
                    --no-owner --no-privileges --clean --if-exists \
                    | gzip > "${BACKUP_FILE}"
                  FILESIZE=$(stat -f%z "${BACKUP_FILE}" 2>/dev/null || stat -c%s "${BACKUP_FILE}")
                  echo "[backup] Completed: ${BACKUP_FILE} (${FILESIZE} bytes)"
                  # Prune backups older than 30 days
                  find /backups -name "superai_db_*.sql.gz" -mtime +30 -delete
                  echo "[backup] Pruned old backups"
              env:
                - name: DB_HOST
                  value: "postgres.superai"
                - name: DB_NAME
                  value: "superai_db"
                - name: DB_USER
                  valueFrom:
                    secretKeyRef:
                      name: superai-db-credentials
                      key: POSTGRES_USER
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: superai-db-credentials
                      key: POSTGRES_PASSWORD
              resources:
                requests:
                  cpu: 100m
                  memory: 256Mi
                limits:
                  cpu: 500m
                  memory: 512Mi
              volumeMounts:
                - name: backup-storage
                  mountPath: /backups
          volumes:
            - name: backup-storage
              persistentVolumeClaim:
                claimName: superai-backup-pvc
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: superai-cleanup
  namespace: eco-superai
  labels:
    app.kubernetes.io/name: superai-platform
    app.kubernetes.io/component: maintenance
spec:
  schedule: "30 3 * * *"
  timeZone: "UTC"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 900
      template:
        metadata:
          labels:
            app.kubernetes.io/name: superai-platform
            app.kubernetes.io/component: maintenance
        spec:
          restartPolicy: OnFailure
          serviceAccountName: superai-worker
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
          containers:
            - name: cleanup
              image: ghcr.io/indestructibleautoops/superai-platform:latest
              command:
                - python
                - -c
                - |
                  import asyncio
                  from src.infrastructure.tasks.worker import cleanup_expired_jobs
                  result = cleanup_expired_jobs()
                  print(f"Cleanup result: {result}")
              envFrom:
                - configMapRef:
                    name: superai-config
                - secretRef:
                    name: superai-secrets
              resources:
                requests:
                  cpu: 50m
                  memory: 128Mi
                limits:
                  cpu: 200m
                  memory: 256Mi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: superai-backup-pvc
  namespace: eco-superai
  labels:
    app.kubernetes.io/name: superai-platform
    app.kubernetes.io/component: backup
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
  resources:
    requests:
      storage: 10Gi